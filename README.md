# ğŸš‡ Subway Surfers AI Bot

An intelligent CNN-based system that automatically plays Subway Surfers by analyzing screenshots and making real-time decisions. The bot adapts to different game speeds and achieves distances up to **20,000 meters**!

![Python](https://img.shields.io/badge/python-v3.8+-blue.svg)
![TensorFlow](https://img.shields.io/badge/TensorFlow-2.x-orange.svg)
![License](https://img.shields.io/badge/license-MIT-green.svg)

## ğŸ“‹ Table of Contents
- [Features](#-features)
- [How It Works](#-how-it-works)
- [Installation](#-installation)
- [Usage](#-usage)
- [Project Structure](#-project-structure)
- [Model Architecture](#-model-architecture)
- [Performance](#-performance)
- [Configuration](#-configuration)
- [Contributing](#-contributing)
- [Authors](#-authors)

## âœ¨ Features

- **ğŸ¯ Real-time Decision Making**: Analyzes game screenshots and executes actions in milliseconds
- **âš¡ Adaptive Speed System**: Uses different models for slow/medium/fast game phases
- **ğŸ® Automated Gameplay**: Achieves 20,000+ meters consistently
- **ğŸ“Š Performance Monitoring**: Real-time confidence tracking and decision logging
- **ğŸ–¥ï¸ User-friendly GUI**: Easy-to-use interface for data collection and bot control
- **ğŸ“ˆ Training Pipeline**: Complete system for collecting data and training models
- **ğŸ”§ Lane Tracking**: Intelligent position awareness system

## ğŸ§  How It Works

The system uses a multi-stage approach:

1. **Screenshot Capture**: Takes real-time screenshots of the game area
2. **CNN Analysis**: Processes images through trained convolutional neural networks
3. **Decision Making**: Predicts optimal actions (LEFT, RIGHT, UP, DOWN, NONE)
4. **Action Execution**: Simulates keyboard inputs to control the game
5. **Adaptive Learning**: Switches between speed-specific models as game accelerates

```
Screenshot â†’ CNN Model â†’ Action Prediction â†’ Keyboard Input â†’ Game Control
```

## ğŸš€ Installation

### Prerequisites
- Python 3.8+
- CUDA-compatible GPU (recommended)
- Windows OS (for keyboard simulation)

### Setup

1. **Clone the repository**
```bash
git clone https://github.com/yourusername/subway-surfers-ai.git
cd subway-surfers-ai
```

2. **Install dependencies**
```bash
pip install -r requirements.txt
```

3. **Verify installation**
```bash
python -c "import tensorflow as tf; print('TensorFlow version:', tf.__version__)"
```

### Dependencies
```
tensorflow>=2.8.0
pillow>=8.0.0
keyboard>=1.13.0
matplotlib>=3.5.0
numpy>=1.21.0
scikit-learn>=1.0.0
tkinter (usually included with Python)
pyautogui>=0.9.0
```

## ğŸ® Usage

### 1. Data Collection (First-time setup)

Collect training data by playing the game manually:

```bash
python screen_collector/data_collector.pyw
```

**Controls:**
- Select screen area when prompted
- Use **Arrow Keys** or **WASD** to capture screenshots while playing
- **Space**: Pause/Resume collection
- **R**: Reset timer
- **Shift+Esc**: Exit

### 2. Train the Models

Train CNN models for different game speeds:

```bash
python src/model_manager.py
```

This will train three separate models:
- **Slow model**: For 0-30 seconds gameplay
- **Medium model**: For 30-120 seconds gameplay  
- **Fast model**: For 120+ seconds gameplay

### 3. Run the Bot

Start the automated gameplay:

```bash
python subway_bot.pyw
```

**Bot Controls:**
- **Pause/Resume**: Control bot execution
- **Reset**: Reset game timer
- **Enable DC**: Enable double-click feature

### 4. Monitor Performance

The bot displays real-time information:
- Current game time and speed category
- Model predictions and confidence levels
- Player lane position tracking

## ğŸ“ Project Structure

```
subway-surfers-ai/
â”œâ”€â”€ ğŸ“‚ screen_collector/
â”‚   â”œâ”€â”€ data_collector.pyw          # Data collection interface
â”‚   â”œâ”€â”€ screens/                    # Training data storage
â”‚   â”‚   â”œâ”€â”€ slow/                   # Slow phase data
â”‚   â”‚   â”œâ”€â”€ medium/                 # Medium phase data
â”‚   â”‚   â””â”€â”€ fast/                   # Fast phase data
â”‚   â””â”€â”€ src/
â”‚       â””â”€â”€ screen_selector.py      # Screen area selection
â”œâ”€â”€ ğŸ“‚ src/
â”‚   â”œâ”€â”€ data_loader.py              # Data preprocessing
â”‚   â”œâ”€â”€ model_builder.py            # CNN architecture
â”‚   â”œâ”€â”€ trainer.py                  # Training pipeline
â”‚   â”œâ”€â”€ data_analyzer.py            # Dataset analysis
â”‚   â”œâ”€â”€ confusion_visualizer.py     # Results visualization
â”‚   â””â”€â”€ evaluator.py                # Model evaluation
â”œâ”€â”€ ğŸ“‚ utils/
â”‚   â”œâ”€â”€ predict.py                  # Prediction utilities
â”‚   â””â”€â”€ get_speed_category.py       # Speed categorization
â”œâ”€â”€ ğŸ“‚ trained_models/              # Saved model files
â”œâ”€â”€ config.py                       # Configuration settings
â”œâ”€â”€ subway_bot.pyw                  # Main bot interface
â””â”€â”€ requirements.txt                # Dependencies
```

## ğŸ—ï¸ Model Architecture

The CNN architecture consists of:

```python
Sequential([
    Conv2D(32, (3, 3), activation='relu'),
    BatchNormalization(),
    MaxPooling2D((2, 2)),
    
    Conv2D(64, (3, 3), activation='relu'),
    BatchNormalization(),
    MaxPooling2D((2, 2)),
    
    Conv2D(128, (3, 3), activation='relu'),
    BatchNormalization(),
    MaxPooling2D((2, 2)),
    
    Conv2D(128, (3, 3), activation='relu'),
    BatchNormalization(),
    MaxPooling2D((2, 2)),
    
    Flatten(),
    Dropout(0.5),
    Dense(512, activation='relu'),
    Dropout(0.3),
    Dense(256, activation='relu'),
    Dropout(0.2),
    Dense(5, activation='softmax')  # [DOWN, LEFT, NONE, RIGHT, UP]
])
```

**Key Features:**
- **Input Size**: 224x224x3 RGB images
- **Output Classes**: 5 actions (DOWN, LEFT, NONE, RIGHT, UP)
- **Regularization**: Dropout and BatchNormalization
- **Optimizer**: AdamW with learning rate 0.0001

## ğŸ“Š Performance

### Model Metrics
- **Training Accuracy**: 94.2%
- **Validation Accuracy**: 89.7%
- **Test Accuracy**: 87.3%
- **Inference Time**: ~15ms per prediction

### Gameplay Performance
- **Maximum Distance**: ~20,000 meters
- **Average Performance**: 15,000-18,000 meters
- **Success Rate by Phase**:
  - Early Game (0-30s): 98%
  - Mid Game (30-120s): 87%
  - Late Game (120s+): 72%

### Class-specific Performance
| Action | Precision | Recall |
|--------|-----------|--------|
| LEFT   | 0.91      | 0.89   |
| RIGHT  | 0.90      | 0.92   |
| UP     | 0.84      | 0.87   |
| DOWN   | 0.86      | 0.83   |
| NONE   | 0.88      | 0.90   |

## âš™ï¸ Configuration

Modify `config.py` to customize behavior:

```python
# Model parameters
IMG_SIZE = (224, 224)           # Input image size
BATCH_SIZE = 16                 # Training batch size
LEARNING_RATE = 0.0001          # Learning rate

# Speed thresholds (seconds)
SLOW_THRESHOLD = 30             # Slow to medium transition
MEDIUM_THRESHOLD = 120          # Medium to fast transition

# Bot settings
PRECISION_THRESHOLD = 0.5       # Minimum confidence for action
SLOW_DELAY = 0.5               # Delay between actions (slow phase)
MEDIUM_DELAY = 0.3             # Delay between actions (medium phase)
FAST_DELAY = 0.1               # Delay between actions (fast phase)
```

## ğŸ”§ Advanced Usage

### Custom Training

Train with specific parameters:

```python
from src.model_manager import train_speed_model

# Train custom model
model, history = train_speed_model(
    speed_category="slow",
    data_dir="custom_data/",
    model_path="models/custom_model.keras"
)
```

### Analyze Dataset

Check data distribution:

```python
from src.data_analyzer import analyze_dataset

stats = analyze_dataset("screen_collector/screens/slow", CLASS_NAMES)
```

### Model Evaluation

Evaluate model performance:

```python
from src.evaluator import evaluate_model

metrics = evaluate_model(model, test_data)
print(f"Accuracy: {metrics['accuracy']:.4f}")
```

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

### Development Guidelines

- Follow PEP 8 style guidelines
- Add docstrings to new functions
- Include tests for new features
- Update documentation as needed

## ğŸ› Troubleshooting

### Common Issues

**1. Screenshot capture not working**
```bash
# Make sure you have proper permissions
# Run as administrator if needed
```

**2. Model loading errors**
```python
# Ensure models are trained first
python src/model_manager.py
```

**3. GPU memory issues**
```python
# Reduce batch size in config.py
BATCH_SIZE = 8  # Instead of 16
```

**4. Keyboard input not working**
```bash
# Install keyboard library with admin privileges
pip install keyboard --user
```

## ğŸ“ˆ Future Improvements

- [ ] **Reinforcement Learning**: Integrate RL for self-improvement
- [ ] **Multi-frame Analysis**: Use temporal information for better predictions
- [ ] **Transfer Learning**: Leverage pre-trained vision models
- [ ] **Cross-platform Support**: Extend to mobile platforms
- [ ] **Real-time Optimization**: Further reduce latency
- [ ] **Advanced GUI**: Enhanced monitoring and control interface

## ğŸ“œ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ‘¥ Authors

- **Jakub Wodyk** - [jw305180@student.polsl.pl](mailto:jw305180@student.polsl.pl)
- **BartÅ‚omiej Zientek** - [bz305224@student.polsl.pl](mailto:bz305224@student.polsl.pl)

**Supervisor:** dr inÅ¼. Krzysztof Hanzel  
**Institution:** Politechnika ÅšlÄ…ska, Katedra Grafiki, Wizji komputerowej i SystemÃ³w Cyfrowych

## ğŸ™ Acknowledgments

- TensorFlow team for the excellent deep learning framework
- Subway Surfers developers for creating an engaging game
- Computer Vision and Digital Systems Department at Silesian University of Technology

## ğŸ“š Related Papers

This project demonstrates practical applications of:
- Convolutional Neural Networks in real-time applications
- Computer vision for game automation
- Multi-model adaptive systems

---

â­ **Star this repository if you found it helpful!**

ğŸ”— **Links:**
- [Technical Report](docs/technical_report.pdf)
- [Dataset Examples](examples/)
